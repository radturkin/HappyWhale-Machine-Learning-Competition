{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe895d6d",
   "metadata": {
    "papermill": {
     "duration": 0.031238,
     "end_time": "2022-04-18T08:45:23.535614",
     "exception": false,
     "start_time": "2022-04-18T08:45:23.504376",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " # Strategy hi im changing things!\n",
    "\n",
    "## Data augmentation\n",
    "- mixup? It's a library that changes images' backgrounds, <span style=\"color:blue\">this sounds cool, and useful<span>\n",
    "- flip horizontally? <span style=\"color:blue\">does this mean upside down? there was an argument against flipping left to right, since each side of the fin is unique and could cause confusion as the left side could be mistaken for the right side.<span>\n",
    "- could borrow other users' datasets to have more datapoints, <span style=\"color:blue\">good idea, especially the cropped ones.<span>\n",
    "\n",
    "## Architecture\n",
    "- Ensemble? use multiple models and average/vote for a result <span style=\"color:blue\">this sounds like a good idea<span>\n",
    "\n",
    "### Backbone/Feature extraction\n",
    "- ResNet? with Triplet loss <span style=\"color:blue\">I like this, though I never done it before<span>\n",
    "- ConvNeXT? <span style=\"color:blue\">unfamiliar<span>\n",
    "    \n",
    "### Head/Classification\n",
    "- Support Vector Classification (SVC)?\n",
    "- Bayesian Ridge?\n",
    "- Gradient Boosting Machine?\n",
    "- Random Forests?\n",
    "   \n",
    "\n",
    "## Validation\n",
    "- KFolds to cross-validate\n",
    "- Use Grad-CAM to see what could be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c60ff1",
   "metadata": {
    "papermill": {
     "duration": 0.029485,
     "end_time": "2022-04-18T08:45:23.595307",
     "exception": false,
     "start_time": "2022-04-18T08:45:23.565822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ideas prioritization:\n",
    "- ResNet101 with tf.keras.layers.Embedding, clustering embeddings with sklearn.cluster.AffinityPropagation.\n",
    "- Data augmentation with ImageDataGenerator (tuning its parameters when we have an idea), maybe using save_to_dir to skip the processing in subsequent fetchs.\n",
    "    - We need to stop the IDG from stretching the images\n",
    "    - We should augment the classes that are in just one or two photos. How? IMG.fit with 100 rows and augment=True yielded 16k images (!)\n",
    "- Use pyimagesearch.gradcam to check if the model is looking at the correct parts of the images.\n",
    "- Use other computer vision pretrained models in an ensemble with tf.keras.layers.Average() or a simple voting (I have a snippet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "565bb102",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T08:45:23.670393Z",
     "iopub.status.busy": "2022-04-18T08:45:23.669862Z",
     "iopub.status.idle": "2022-04-18T08:45:29.543273Z",
     "shell.execute_reply": "2022-04-18T08:45:29.543896Z",
     "shell.execute_reply.started": "2022-04-18T08:39:26.224636Z"
    },
    "papermill": {
     "duration": 5.917382,
     "end_time": "2022-04-18T08:45:29.544164",
     "exception": false,
     "start_time": "2022-04-18T08:45:23.626782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from tqdm.autonotebook import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import os, gc\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import cv2\n",
    "# !pip install -q -U tensorflow-addons\n",
    "# import tensorflow_addons as tfa\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a73967d",
   "metadata": {
    "papermill": {
     "duration": 0.029829,
     "end_time": "2022-04-18T08:45:29.604637",
     "exception": false,
     "start_time": "2022-04-18T08:45:29.574808",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data preparation\n",
    "### File names retrieval from labeled CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b158ba8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T08:45:29.668180Z",
     "iopub.status.busy": "2022-04-18T08:45:29.667531Z",
     "iopub.status.idle": "2022-04-18T08:45:29.670144Z",
     "shell.execute_reply": "2022-04-18T08:45:29.669724Z",
     "shell.execute_reply.started": "2022-04-18T08:39:32.467982Z"
    },
    "papermill": {
     "duration": 0.035785,
     "end_time": "2022-04-18T08:45:29.670246",
     "exception": false,
     "start_time": "2022-04-18T08:45:29.634461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_SUBSET = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "970f734c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T08:45:29.734224Z",
     "iopub.status.busy": "2022-04-18T08:45:29.733536Z",
     "iopub.status.idle": "2022-04-18T08:45:29.813435Z",
     "shell.execute_reply": "2022-04-18T08:45:29.813849Z",
     "shell.execute_reply.started": "2022-04-18T08:39:32.477875Z"
    },
    "papermill": {
     "duration": 0.113564,
     "end_time": "2022-04-18T08:45:29.813994",
     "exception": false,
     "start_time": "2022-04-18T08:45:29.700430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/happy-whale-and-dolphin/train.csv\")\n",
    "train_df = train_df#[:DATA_SUBSET]\n",
    "\n",
    "# To get only top 10 most photographed whales\n",
    "# famous_whale_ids = train_df[\"individual_id\"].value_counts()[:10].index.tolist()\n",
    "# train_df = train_df[train_df['individual_id'].isin(famous_whale_ids)]\n",
    "# train_df[\"individual_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c045038",
   "metadata": {
    "papermill": {
     "duration": 0.03067,
     "end_time": "2022-04-18T08:45:29.875249",
     "exception": false,
     "start_time": "2022-04-18T08:45:29.844579",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6a2fb65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T08:45:29.967408Z",
     "iopub.status.busy": "2022-04-18T08:45:29.966591Z",
     "iopub.status.idle": "2022-04-18T08:45:30.202804Z",
     "shell.execute_reply": "2022-04-18T08:45:30.203230Z",
     "shell.execute_reply.started": "2022-04-18T08:39:32.572297Z"
    },
    "papermill": {
     "duration": 0.297987,
     "end_time": "2022-04-18T08:45:30.203407",
     "exception": false,
     "start_time": "2022-04-18T08:45:29.905420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_labels(y):\n",
    "    values = np.array(y)\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    y = onehot_encoded\n",
    "    return y, label_encoder, onehot_encoder\n",
    "y, label_encoder, onehot_encoder = prepare_labels(train_df['individual_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4ec394",
   "metadata": {
    "papermill": {
     "duration": 0.029684,
     "end_time": "2022-04-18T08:45:30.263549",
     "exception": false,
     "start_time": "2022-04-18T08:45:30.233865",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc2efc38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T08:45:30.332486Z",
     "iopub.status.busy": "2022-04-18T08:45:30.330347Z",
     "iopub.status.idle": "2022-04-18T08:45:30.334624Z",
     "shell.execute_reply": "2022-04-18T08:45:30.334196Z",
     "shell.execute_reply.started": "2022-04-18T08:39:32.586484Z"
    },
    "papermill": {
     "duration": 0.041441,
     "end_time": "2022-04-18T08:45:30.334733",
     "exception": false,
     "start_time": "2022-04-18T08:45:30.293292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def crop_resize_and_save(df, target_size, subset: ['train', 'test']):\n",
    "    save_dir = f'/kaggle/working/{subset}_resized/'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    for filename in tqdm(df['image']):\n",
    "        img = image.load_img(f\"../input/happy-whale-and-dolphin/{subset}_images/\"+filename)\n",
    "        x = image.img_to_array(img)\n",
    "        scale = max(np.array(target_size)/np.array(x.shape[:-1]))\n",
    "        x = cv2.resize(x, None, fx = scale, fy = scale, interpolation=cv2.INTER_CUBIC)\n",
    "        crops = (np.array(x.shape[:-1])-np.array(target_size))//2\n",
    "        crops = crops.astype(int)\n",
    "        x = x[crops[0]:target_size[0]+crops[0], crops[1]:target_size[1]+crops[1], :]\n",
    "        image.save_img(save_dir+filename, x)\n",
    "    return f'/kaggle/working/{subset}_resized/'\n",
    "\n",
    "target_size=(300, 300) # what efficientNet expects\n",
    "                        # EfficientNetB0\t224\n",
    "                        # EfficientNetB1\t240\n",
    "                        # EfficientNetB2\t260\n",
    "                        # EfficientNetB3\t300\n",
    "                        # EfficientNetB4\t380\n",
    "                        # EfficientNetB5\t456\n",
    "                        # EfficientNetB6\t528\n",
    "                        # EfficientNetB7\t600\n",
    "train_image_dir = \"../input/happy-whale-and-dolphin/train_images/\"\n",
    "# train_image_dir = crop_resize_and_save(train_df, target_size, 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cd0748",
   "metadata": {
    "papermill": {
     "duration": 0.029559,
     "end_time": "2022-04-18T08:45:30.394242",
     "exception": false,
     "start_time": "2022-04-18T08:45:30.364683",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73c4b216",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T08:45:30.463552Z",
     "iopub.status.busy": "2022-04-18T08:45:30.462775Z",
     "iopub.status.idle": "2022-04-18T08:45:30.465353Z",
     "shell.execute_reply": "2022-04-18T08:45:30.464833Z",
     "shell.execute_reply.started": "2022-04-18T08:39:32.599389Z"
    },
    "papermill": {
     "duration": 0.041243,
     "end_time": "2022-04-18T08:45:30.465462",
     "exception": false,
     "start_time": "2022-04-18T08:45:30.424219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_gen = ImageDataGenerator(rescale=1./255, validation_split=0.1, rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range= 0.2,\n",
    "    zoom_range = 0.3,\n",
    ")\n",
    "flow_options=dict(\n",
    "        x_col='image',\n",
    "        y_col='individual_id',\n",
    "        directory=train_image_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        classes=list(label_encoder.classes_),\n",
    "        augment=True,\n",
    ")\n",
    "def arcface_gen(gen, y=True):\n",
    "    while True:\n",
    "        x_batch = next(gen)\n",
    "        if type(x_batch) is tuple:\n",
    "            x_batch, y_batch = x_batch\n",
    "            y_batch_0 = y_batch\n",
    "            if not y:\n",
    "                y_batch_0 = np.zeros((len(x_batch), len(label_encoder.classes_)))\n",
    "            yield [x_batch, y_batch_0], y_batch\n",
    "        else:\n",
    "            y_batch = np.zeros((len(x_batch), len(label_encoder.classes_)))\n",
    "            yield [x_batch, y_batch], y_batch\n",
    "\n",
    "# X_train = X_gen.flow_from_dataframe(train_df, **flow_options, subset='training')\n",
    "# X_validation = X_gen.flow_from_dataframe(train_df, **flow_options, subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbc3a91",
   "metadata": {
    "papermill": {
     "duration": 0.029652,
     "end_time": "2022-04-18T08:45:30.525047",
     "exception": false,
     "start_time": "2022-04-18T08:45:30.495395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d51af663",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T08:45:30.589874Z",
     "iopub.status.busy": "2022-04-18T08:45:30.589236Z",
     "iopub.status.idle": "2022-04-18T08:45:30.591456Z",
     "shell.execute_reply": "2022-04-18T08:45:30.591886Z",
     "shell.execute_reply.started": "2022-04-18T08:39:32.611418Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.036321,
     "end_time": "2022-04-18T08:45:30.591999",
     "exception": false,
     "start_time": "2022-04-18T08:45:30.555678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_items(gen):\n",
    "    for e, i in zip(arcface_gen(gen), range(10)):\n",
    "        print(e[0][0].shape, e[0][1], e[1])\n",
    "# show_items(X_train)\n",
    "# show_items(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7698ab04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T08:45:30.658085Z",
     "iopub.status.busy": "2022-04-18T08:45:30.657279Z",
     "iopub.status.idle": "2022-04-18T08:45:30.659010Z",
     "shell.execute_reply": "2022-04-18T08:45:30.659462Z",
     "shell.execute_reply.started": "2022-04-18T08:39:32.621213Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.037217,
     "end_time": "2022-04-18T08:45:30.659581",
     "exception": false,
     "start_time": "2022-04-18T08:45:30.622364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for plotting augmented images\n",
    "def plotImages(train_data_gen):\n",
    "    #plotting augmentations of same image\n",
    "    images_arr = [train_data_gen[1][0][0] for i in range(5)]\n",
    "    fig, axes = plt.subplots(len(images_arr), 1, figsize=(5,len(images_arr) * 3))\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "          ax.imshow(img)\n",
    "          ax.axis('off')\n",
    "   \n",
    "    plt.show()\n",
    "\n",
    "# plotImages(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06a3b829",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T08:45:30.725579Z",
     "iopub.status.busy": "2022-04-18T08:45:30.724839Z",
     "iopub.status.idle": "2022-04-18T08:45:30.727184Z",
     "shell.execute_reply": "2022-04-18T08:45:30.726767Z",
     "shell.execute_reply.started": "2022-04-18T08:39:32.630106Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.037828,
     "end_time": "2022-04-18T08:45:30.727282",
     "exception": false,
     "start_time": "2022-04-18T08:45:30.689454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preview_augmented_data(image_data_generator):\n",
    "    X_preview = image_data_generator.flow_from_dataframe(\n",
    "        train_df[:32],\n",
    "        **flow_options,\n",
    "        save_to_dir='/kaggle/working/aug_data_preview')\n",
    "\n",
    "    shutil.rmtree(X_preview.save_to_dir, ignore_errors=True)\n",
    "    os.makedirs(X_preview.save_to_dir)\n",
    "        \n",
    "    fig, axes = plt.subplots(4, 8, figsize=(30, 15))\n",
    "    axes = axes.flatten()\n",
    "    image_batch = next(X_preview)[0]\n",
    "    for i, (ax, ai) in enumerate(zip(axes, image_batch)):\n",
    "        ax.imshow(ai)\n",
    "\n",
    "# preview_augmented_data(X_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1093281c",
   "metadata": {
    "papermill": {
     "duration": 0.029847,
     "end_time": "2022-04-18T08:45:30.786904",
     "exception": false,
     "start_time": "2022-04-18T08:45:30.757057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b62346de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T08:45:30.859222Z",
     "iopub.status.busy": "2022-04-18T08:45:30.850139Z",
     "iopub.status.idle": "2022-04-18T08:45:30.861480Z",
     "shell.execute_reply": "2022-04-18T08:45:30.861033Z",
     "shell.execute_reply.started": "2022-04-18T08:39:32.642641Z"
    },
    "papermill": {
     "duration": 0.044991,
     "end_time": "2022-04-18T08:45:30.861584",
     "exception": false,
     "start_time": "2022-04-18T08:45:30.816593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# src: https://github.com/4uiiurz1/keras-arcface/blob/master/metrics.py\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras import regularizers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class ArcFace(Layer):\n",
    "    def __init__(self, n_classes=10, s=30.0, m=0.50, regularizer=None, **kwargs):\n",
    "        super(ArcFace, self).__init__(**kwargs)\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.regularizer = regularizers.get(regularizer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcFace, self).build(input_shape[0])\n",
    "        self.W = self.add_weight(name='W',\n",
    "                                shape=(input_shape[0][-1], self.n_classes),\n",
    "                                initializer='glorot_uniform',\n",
    "                                trainable=True,\n",
    "                                regularizer=self.regularizer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, y = inputs\n",
    "        c = K.shape(x)[-1]\n",
    "        # normalize feature\n",
    "        x = tf.nn.l2_normalize(x, axis=1)\n",
    "        # normalize weights\n",
    "        W = tf.nn.l2_normalize(self.W, axis=0)\n",
    "        # dot product\n",
    "        logits = x @ W\n",
    "        # add margin\n",
    "        # clip logits to prevent zero division when backward\n",
    "        theta = tf.acos(K.clip(logits, -1.0 + K.epsilon(), 1.0 - K.epsilon()))\n",
    "        target_logits = tf.cos(theta + self.m)\n",
    "        # sin = tf.sqrt(1 - logits**2)\n",
    "        # cos_m = tf.cos(logits)\n",
    "        # sin_m = tf.sin(logits)\n",
    "        # target_logits = logits * cos_m - sin * sin_m\n",
    "        #\n",
    "        logits = logits * (1 - y) + target_logits * y\n",
    "        # feature re-scale\n",
    "        logits *= self.s\n",
    "        out = tf.nn.softmax(logits)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.n_classes)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'n_classes': self.n_classes,\n",
    "            's': self.s,\n",
    "            'm': self.m,\n",
    "            'regularizer': self.regularizer,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a08a5844",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T08:45:30.935577Z",
     "iopub.status.busy": "2022-04-18T08:45:30.934858Z",
     "iopub.status.idle": "2022-04-18T08:45:30.936813Z",
     "shell.execute_reply": "2022-04-18T08:45:30.937343Z",
     "shell.execute_reply.started": "2022-04-18T08:39:32.661076Z"
    },
    "papermill": {
     "duration": 0.045069,
     "end_time": "2022-04-18T08:45:30.937478",
     "exception": false,
     "start_time": "2022-04-18T08:45:30.892409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#I had to run this code twice to avoid errors\n",
    "def get_custom_model():\n",
    "    inputs = tf.keras.layers.Input((256, 256, 3))\n",
    "    outputs = tf.keras.layers.Conv2D(64, kernel_size=(3, 3))(inputs)\n",
    "    outputs = tf.keras.layers.MaxPooling2D()(outputs)\n",
    "    outputs = tf.keras.layers.Conv2D(32, kernel_size=(3, 3))(outputs)\n",
    "    outputs = tf.keras.layers.MaxPooling2D()(outputs)\n",
    "    outputs = tf.keras.layers.Flatten()(outputs)\n",
    "    outputs = tf.keras.layers.Dense(80)(outputs)\n",
    "    outputs = tf.keras.layers.Dense(30)(outputs)\n",
    "    outputs = tf.keras.layers.Dense(len(label_encoder.classes_))(outputs)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def get_arceff_model(show_summary=False):\n",
    "    from keras.backend import cast\n",
    "    n_classes = len(label_encoder.classes_)\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=target_size+(3,), name=\"input_image\")\n",
    "    labels = tf.keras.layers.Input(shape=(n_classes,), name=\"input_label\")\n",
    "    \n",
    "    base_model = tf.keras.applications.EfficientNetB3(include_top=False)\n",
    "#     base_model = tf.keras.applications.resnet50.ResNet50(include_top=False)\n",
    "    base_model.trainable=False\n",
    "    outputs = base_model(inputs)\n",
    "    outputs = tf.keras.layers.BatchNormalization(name='bn')(outputs)\n",
    "    outputs = tf.keras.layers.Flatten()(outputs)\n",
    "    outputs = tf.keras.layers.Dense(512, kernel_initializer='he_normal', name='embeddings')(outputs)\n",
    "    outputs = tf.keras.layers.Dropout(0.1)(outputs)\n",
    "\n",
    "#     outputs = tf.keras.layers.GlobalMaxPooling2D(name=\"gap\")(outputs)\n",
    "#     outputs = tf.keras.layers.LeakyReLU(400)(outputs)\n",
    "#     outputs = tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(outputs) # L2 normalize embeddings\n",
    "    outputs = ArcFace(n_classes, name='arc')([outputs, labels])\n",
    "    \n",
    "    model = tf.keras.Model([inputs, labels], outputs)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=0.05),\n",
    "                  metrics=['accuracy'])\n",
    "    if show_summary:\n",
    "        model.summary(line_length=150)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c34ffe",
   "metadata": {
    "papermill": {
     "duration": 0.029652,
     "end_time": "2022-04-18T08:45:30.997361",
     "exception": false,
     "start_time": "2022-04-18T08:45:30.967709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2356ba46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T08:45:31.070800Z",
     "iopub.status.busy": "2022-04-18T08:45:31.070046Z",
     "iopub.status.idle": "2022-04-18T17:03:25.066791Z",
     "shell.execute_reply": "2022-04-18T17:03:25.067570Z",
     "shell.execute_reply.started": "2022-04-18T08:39:32.676924Z"
    },
    "papermill": {
     "duration": 29874.040529,
     "end_time": "2022-04-18T17:03:25.067744",
     "exception": false,
     "start_time": "2022-04-18T08:45:31.027215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1 started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 08:45:31.174847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 08:45:31.274447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 08:45:31.275199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 08:45:31.276475: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-18 08:45:31.277648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 08:45:31.278351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 08:45:31.279006: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 08:45:33.039358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 08:45:33.040244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 08:45:33.040968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 08:45:33.041563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
      "43941888/43941136 [==============================] - 0s 0us/step\n",
      "43950080/43941136 [==============================] - 0s 0us/step\n",
      "Model: \"model\"\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                     Output Shape                     Param #           Connected to                                      \n",
      "======================================================================================================================================================\n",
      "input_image (InputLayer)                         [(None, 300, 300, 3)]            0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "efficientnetb3 (Functional)                      (None, None, None, 1536)         10783535          input_image[0][0]                                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "bn (BatchNormalization)                          (None, 9, 9, 1536)               6144              efficientnetb3[0][0]                              \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "flatten (Flatten)                                (None, 124416)                   0                 bn[0][0]                                          \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "embeddings (Dense)                               (None, 512)                      63701504          flatten[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "dropout (Dropout)                                (None, 512)                      0                 embeddings[0][0]                                  \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "input_label (InputLayer)                         [(None, 15587)]                  0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "arc (ArcFace)                                    (None, 15587)                    7980544           dropout[0][0]                                     \n",
      "                                                                                                    input_label[0][0]                                 \n",
      "======================================================================================================================================================\n",
      "Total params: 82,471,727\n",
      "Trainable params: 71,685,120\n",
      "Non-trainable params: 10,786,607\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Found 40826 validated image filenames belonging to 15587 classes.\n",
      "Found 10207 validated image filenames belonging to 15587 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 08:46:52.410257: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 08:47:01.111831: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1275/1275 [==============================] - 4955s 4s/step - loss: 12.7726 - accuracy: 0.0000e+00 - val_loss: 8.1997 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 8.19972, saving model to /kaggle/working/model_weights.hdf5\n",
      "Epoch 2/6\n",
      "1275/1275 [==============================] - 4932s 4s/step - loss: 11.1602 - accuracy: 0.0000e+00 - val_loss: 7.6007 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss improved from 8.19972 to 7.60069, saving model to /kaggle/working/model_weights.hdf5\n",
      "Epoch 3/6\n",
      "1275/1275 [==============================] - 4853s 4s/step - loss: 11.0349 - accuracy: 0.0000e+00 - val_loss: 7.4977 - val_accuracy: 0.3324\n",
      "\n",
      "Epoch 00003: val_loss improved from 7.60069 to 7.49766, saving model to /kaggle/working/model_weights.hdf5\n",
      "Epoch 4/6\n",
      "1275/1275 [==============================] - 4921s 4s/step - loss: 10.9859 - accuracy: 0.0000e+00 - val_loss: 7.4042 - val_accuracy: 0.6659\n",
      "\n",
      "Epoch 00004: val_loss improved from 7.49766 to 7.40423, saving model to /kaggle/working/model_weights.hdf5\n",
      "Epoch 5/6\n",
      "1275/1275 [==============================] - 5072s 4s/step - loss: 10.9637 - accuracy: 0.0000e+00 - val_loss: 7.3400 - val_accuracy: 0.5070\n",
      "\n",
      "Epoch 00005: val_loss improved from 7.40423 to 7.34001, saving model to /kaggle/working/model_weights.hdf5\n",
      "Epoch 6/6\n",
      "1275/1275 [==============================] - 4993s 4s/step - loss: 10.9380 - accuracy: 0.0000e+00 - val_loss: 7.2766 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00006: val_loss improved from 7.34001 to 7.27659, saving model to /kaggle/working/model_weights.hdf5\n",
      "New best model: val_loss 7.2765936851501465\n",
      "Fold finished ︵‿︵‿︵‿︵‿︵‿︵‿︵‿︵‿︵‿︵‿\n",
      "All done.\n"
     ]
    }
   ],
   "source": [
    "input_model_path = \"../input/modelhdf5/model_weights.hdf5\"\n",
    "checkpoint_filepath = '/kaggle/working/model_weights.hdf5'\n",
    "best_weights_filepath = '/kaggle/working/best_model_weights.hdf5'\n",
    "\n",
    "# os.remove(best_weights_filepath)\n",
    "if os.path.exists(best_weights_filepath):\n",
    "    model = get_arceff_model(show_summary=True)\n",
    "    model.load_weights(best_weights_filepath)\n",
    "    print('weights loaded')\n",
    "else:\n",
    "    min_val_loss = 99999\n",
    "\n",
    "    fold_current, fold_max = 0, 5\n",
    "    kfold = KFold(n_splits=fold_max)\n",
    "    for train, test in kfold.split(train_df):\n",
    "        fold_current += 1\n",
    "        print(f'\\nFold {fold_current} started.')\n",
    "\n",
    "        model = get_arceff_model(show_summary=fold_current==1)\n",
    "        \n",
    "        X_train = X_gen.flow_from_dataframe(train_df.iloc[train], **flow_options)#, subset='training')\n",
    "        X_validation = X_gen.flow_from_dataframe(train_df.iloc[test], **flow_options)#, subset='validation')\n",
    "        \n",
    "        history = model.fit(arcface_gen(X_train),\n",
    "            batch_size = X_train.batch_size, #havent tried other batch sizes\n",
    "            steps_per_epoch = len(train)//X_train.batch_size,\n",
    "\n",
    "            validation_data = arcface_gen(X_validation),\n",
    "            validation_batch_size = X_validation.batch_size,\n",
    "            validation_steps = len(test)//X_validation.batch_size,\n",
    "\n",
    "            epochs=6, #something weird was happening with the loss and accuracy values after 10 epochs\n",
    "\n",
    "            verbose=1,\n",
    "            callbacks=[ModelCheckpoint(checkpoint_filepath, verbose=1, save_best_only=True, save_weights_only=True)],\n",
    "        )\n",
    "        \n",
    "        fold_min_val_loss = min(history.history['val_loss'])\n",
    "        if fold_min_val_loss < min_val_loss:\n",
    "            os.rename(checkpoint_filepath, best_weights_filepath)\n",
    "            min_val_loss = fold_min_val_loss\n",
    "            print(f'New best model: val_loss {min_val_loss}')\n",
    "        print('Fold finished ︵‿︵‿︵‿︵‿︵‿︵‿︵‿︵‿︵‿︵‿')\n",
    "        break\n",
    "        \n",
    "    print('All done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2095ad8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T17:03:29.864922Z",
     "iopub.status.busy": "2022-04-18T17:03:29.863931Z",
     "iopub.status.idle": "2022-04-18T17:03:30.714527Z",
     "shell.execute_reply": "2022-04-18T17:03:30.714040Z",
     "shell.execute_reply.started": "2022-04-18T08:42:17.870645Z"
    },
    "papermill": {
     "duration": 3.24718,
     "end_time": "2022-04-18T17:03:30.714671",
     "exception": false,
     "start_time": "2022-04-18T17:03:27.467491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_weights(best_weights_filepath)\n",
    "prediction_model = tf.keras.Model(inputs=model.inputs[0], outputs=model.get_layer('embeddings').output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c3a338",
   "metadata": {
    "papermill": {
     "duration": 2.716322,
     "end_time": "2022-04-18T17:03:36.101855",
     "exception": false,
     "start_time": "2022-04-18T17:03:33.385533",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Embeddings encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b6a51be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T17:03:40.882979Z",
     "iopub.status.busy": "2022-04-18T17:03:40.876118Z",
     "iopub.status.idle": "2022-04-18T17:04:17.777848Z",
     "shell.execute_reply": "2022-04-18T17:04:17.778521Z",
     "shell.execute_reply.started": "2022-04-18T08:42:18.575166Z"
    },
    "papermill": {
     "duration": 39.281638,
     "end_time": "2022-04-18T17:04:17.778699",
     "exception": false,
     "start_time": "2022-04-18T17:03:38.497061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51033 validated image filenames belonging to 15587 classes.\n"
     ]
    }
   ],
   "source": [
    "prediction_flow_options = flow_options.copy()\n",
    "prediction_flow_options.update(dict(shuffle = False, batch_size=1))\n",
    "train_pred_gen = X_gen.flow_from_dataframe(train_df, **prediction_flow_options)\n",
    "\n",
    "# validation_df = train_df[:100].copy()\n",
    "# val_pred_gen = X_gen.flow_from_dataframe(validation_df, **prediction_flow_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90f7394b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T17:04:22.530853Z",
     "iopub.status.busy": "2022-04-18T17:04:22.530229Z",
     "iopub.status.idle": "2022-04-18T18:32:19.003485Z",
     "shell.execute_reply": "2022-04-18T18:32:19.003008Z",
     "shell.execute_reply.started": "2022-04-18T08:42:18.613584Z"
    },
    "papermill": {
     "duration": 5278.851889,
     "end_time": "2022-04-18T18:32:19.003621",
     "exception": false,
     "start_time": "2022-04-18T17:04:20.151732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51033/51033 [==============================] - 5271s 103ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(n_neighbors=11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this just makes embeddings (at least the arcface model)\n",
    "def predict_embeddings(model, gen):\n",
    "    embedded_features = prediction_model.predict(gen, verbose=1)\n",
    "    return embedded_features / np.linalg.norm(embedded_features, axis=1, keepdims=True)\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=11)\n",
    "nn.fit(predict_embeddings(prediction_model, train_pred_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2acd17f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T18:32:49.698594Z",
     "iopub.status.busy": "2022-04-18T18:32:49.697795Z",
     "iopub.status.idle": "2022-04-18T18:32:49.700239Z",
     "shell.execute_reply": "2022-04-18T18:32:49.699831Z",
     "shell.execute_reply.started": "2022-04-18T08:42:48.912766Z"
    },
    "papermill": {
     "duration": 15.088065,
     "end_time": "2022-04-18T18:32:49.700380",
     "exception": false,
     "start_time": "2022-04-18T18:32:34.612315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get pred from KNN\n",
    "def embeddings_to_ids(embeddings):\n",
    "    neighbor_too_far_new_individual_threshold = 0.00005 # the less the more new_individuals appear\n",
    "\n",
    "    dists, inds = nn.kneighbors(X=embeddings, return_distance=True)\n",
    "\n",
    "    # get labels of the neighbours\n",
    "    pred_ids =[]\n",
    "    for ind, dis in zip(inds, dists):\n",
    "        neighs = pd.DataFrame({'id': train_df.iloc[ind]['individual_id'], 'dist': dis})\n",
    "        neighs = neighs.append({'id': 'new_individual', 'dist': neighbor_too_far_new_individual_threshold}, ignore_index=True)\n",
    "        group = neighs.groupby('id')\n",
    "        neighs['dist'] = group[['dist']].transform(lambda x: sum(x)/len(x))\n",
    "        ids = neighs.sort_values('dist')['id'].unique()[:5].tolist()\n",
    "        pred_ids.append(ids)\n",
    "\n",
    "    fist_dist = dists[:,0].ravel()\n",
    "    mean_first_dist = np.mean(fist_dist)\n",
    "    above_average_distances = sorted(fist_dist[fist_dist>mean_first_dist], reverse=True)\n",
    "    print('top 15% longest distances: ', above_average_distances[:1+int(len(above_average_distances)/7)])\n",
    "    print('our threshold: ', neighbor_too_far_new_individual_threshold)\n",
    "    return pred_ids\n",
    "\n",
    "# val_embeddings = predict_embeddings(prediction_model, val_pred_gen)\n",
    "# pred_ids = embeddings_to_ids(val_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46abf9b4",
   "metadata": {
    "papermill": {
     "duration": 15.344694,
     "end_time": "2022-04-18T18:33:20.958990",
     "exception": false,
     "start_time": "2022-04-18T18:33:05.614296",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Visualizing validation set's score and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22f89beb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T18:33:51.345502Z",
     "iopub.status.busy": "2022-04-18T18:33:51.344797Z",
     "iopub.status.idle": "2022-04-18T18:33:51.347730Z",
     "shell.execute_reply": "2022-04-18T18:33:51.347261Z",
     "shell.execute_reply.started": "2022-04-18T08:42:48.924198Z"
    },
    "papermill": {
     "duration": 14.87395,
     "end_time": "2022-04-18T18:33:51.347845",
     "exception": false,
     "start_time": "2022-04-18T18:33:36.473895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_per_image(label, predictions):   \n",
    "    try:\n",
    "        return 1 / (predictions[:5].index(label) + 1)\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "\n",
    "def map_per_set(labels, predictions):\n",
    "    return [map_per_image(l, p) for l,p in zip(labels, predictions)]\n",
    "\n",
    "# validation_df['pred_ids'] = [' '.join(label_list) for label_list in pred_ids]\n",
    "# ap5 = map_per_set(validation_df['individual_id'].tolist(), pred_ids)\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "# print(validation_df)\n",
    "# print(ap5, np.mean(ap5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6e36d0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T18:34:21.868117Z",
     "iopub.status.busy": "2022-04-18T18:34:21.867391Z",
     "iopub.status.idle": "2022-04-18T18:34:21.870660Z",
     "shell.execute_reply": "2022-04-18T18:34:21.870172Z",
     "shell.execute_reply.started": "2022-04-18T08:42:48.944496Z"
    },
    "papermill": {
     "duration": 15.168211,
     "end_time": "2022-04-18T18:34:21.870782",
     "exception": false,
     "start_time": "2022-04-18T18:34:06.702571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scatter3D(embeddings, pred_labels, total_labels):\n",
    "    tsne = TSNE(3, verbose=1)\n",
    "    tsne_proj = tsne.fit_transform(embeddings)\n",
    "    cmap = cm.get_cmap('rainbow')\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "#     print(np.unique(pred_labels, return_counts=True))\n",
    "    for i, lab in enumerate(total_labels):\n",
    "        indices = np.array([total_labels.index(p) for p in pred_labels])  == i\n",
    "        ax.scatter(tsne_proj[indices, 0],\n",
    "                   tsne_proj[indices, 1],\n",
    "                   tsne_proj[indices, 2],\n",
    "                   c=np.array(cmap(i)).reshape(1, 4),\n",
    "                   label=lab,\n",
    "                   alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "# scatter3D(val_embeddings, np.array(pred_ids)[:, 0], train_df['individual_id'].unique().tolist()+['new_individual'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69371df6",
   "metadata": {
    "papermill": {
     "duration": 14.990506,
     "end_time": "2022-04-18T18:34:52.215562",
     "exception": false,
     "start_time": "2022-04-18T18:34:37.225056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prediction\n",
    "### File names retrieval from test_images folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d281895",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T18:35:22.501034Z",
     "iopub.status.busy": "2022-04-18T18:35:22.500224Z",
     "iopub.status.idle": "2022-04-18T18:35:22.935374Z",
     "shell.execute_reply": "2022-04-18T18:35:22.934768Z",
     "shell.execute_reply.started": "2022-04-18T08:42:48.958134Z"
    },
    "papermill": {
     "duration": 15.847088,
     "end_time": "2022-04-18T18:35:22.935499",
     "exception": false,
     "start_time": "2022-04-18T18:35:07.088411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = os.listdir(\"../input/happy-whale-and-dolphin/test_images\")\n",
    "test_df = pd.DataFrame(test, columns=['image'])#[:DATA_SUBSET]\n",
    "test_df['predictions'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ee169ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T18:35:53.472596Z",
     "iopub.status.busy": "2022-04-18T18:35:53.472022Z",
     "iopub.status.idle": "2022-04-18T18:35:53.484594Z",
     "shell.execute_reply": "2022-04-18T18:35:53.484151Z",
     "shell.execute_reply.started": "2022-04-18T08:42:49.509753Z"
    },
    "papermill": {
     "duration": 15.250414,
     "end_time": "2022-04-18T18:35:53.484724",
     "exception": false,
     "start_time": "2022-04-18T18:35:38.234310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cd50701ae53ed8.jpg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>177269f927ed34.jpg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9137934396d804.jpg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c28365a55a0dfe.jpg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1a40b7b382923a.jpg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                image predictions\n",
       "0  cd50701ae53ed8.jpg            \n",
       "1  177269f927ed34.jpg            \n",
       "2  9137934396d804.jpg            \n",
       "3  c28365a55a0dfe.jpg            \n",
       "4  1a40b7b382923a.jpg            "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd32dd78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T18:36:24.109262Z",
     "iopub.status.busy": "2022-04-18T18:36:24.108450Z",
     "iopub.status.idle": "2022-04-18T18:36:24.110514Z",
     "shell.execute_reply": "2022-04-18T18:36:24.110879Z",
     "shell.execute_reply.started": "2022-04-18T08:42:49.525147Z"
    },
    "papermill": {
     "duration": 15.487628,
     "end_time": "2022-04-18T18:36:24.111021",
     "exception": false,
     "start_time": "2022-04-18T18:36:08.623393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The same cropping process as the train dataset. Test images need\n",
    "# to undergo the same process for the model to predict on them.\n",
    "test_image_dir = \"../input/happy-whale-and-dolphin/test_images/\"\n",
    "# test_image_dir = crop_resize_and_save(test_df, target_size, 'test') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a51a77f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T18:36:54.743004Z",
     "iopub.status.busy": "2022-04-18T18:36:54.742250Z",
     "iopub.status.idle": "2022-04-18T18:37:02.660621Z",
     "shell.execute_reply": "2022-04-18T18:37:02.659978Z",
     "shell.execute_reply.started": "2022-04-18T08:43:26.988755Z"
    },
    "papermill": {
     "duration": 23.700985,
     "end_time": "2022-04-18T18:37:02.660780",
     "exception": false,
     "start_time": "2022-04-18T18:36:38.959795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27956 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "target_dir = test_image_dir.rstrip('/').split('/')[-1]\n",
    "parent_dir = test_image_dir.rstrip('/').rstrip(target_dir)\n",
    "\n",
    "Y_gen = ImageDataGenerator(rescale=1./255)\n",
    "Y_flow = Y_gen.flow_from_directory(\n",
    "        directory=parent_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        class_mode=None,\n",
    "        classes=[target_dir])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05c7cee",
   "metadata": {
    "papermill": {
     "duration": 15.256459,
     "end_time": "2022-04-18T18:37:33.093351",
     "exception": false,
     "start_time": "2022-04-18T18:37:17.836892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Embeddings encoding and label inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c2e2fe1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T18:38:03.542424Z",
     "iopub.status.busy": "2022-04-18T18:38:03.541775Z",
     "iopub.status.idle": "2022-04-18T19:32:58.833294Z",
     "shell.execute_reply": "2022-04-18T19:32:58.833814Z",
     "shell.execute_reply.started": "2022-04-18T08:43:27.102382Z"
    },
    "papermill": {
     "duration": 3310.662577,
     "end_time": "2022-04-18T19:32:58.833966",
     "exception": false,
     "start_time": "2022-04-18T18:37:48.171389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27956/27956 [==============================] - 2542s 91ms/step\n",
      "top 15% longest distances:  [0.00016727880920975574, 0.00014104246452978405, 0.00013744163969038928, 0.00012032016375067623, 5.8823287403513595e-05, 5.1762769696894975e-05, 5.1644458652846275e-05, 5.120729605187965e-05, 5.045594672119291e-05, 4.971121021326796e-05, 4.8812141321342235e-05, 4.856537518595193e-05, 4.695087452278052e-05, 4.6499071430694194e-05, 4.527443704065973e-05, 4.509320713634908e-05, 4.399112434406288e-05, 4.373029136149653e-05, 4.3621644317435724e-05, 4.254937846295963e-05, 4.239262904350296e-05, 4.19356577796037e-05, 4.114570781977967e-05, 4.113814903525142e-05, 4.0984138545299256e-05, 4.086080351546733e-05, 4.051872654581746e-05, 3.982780472392032e-05, 3.933725911187893e-05, 3.932195665461842e-05, 3.811026215004178e-05, 3.784974062662396e-05, 3.7503751120489865e-05, 3.7462136187138865e-05, 3.745577679883919e-05, 3.738718057754946e-05, 3.6937387776450546e-05, 3.6836272149830494e-05, 3.674660388471653e-05, 3.669628220100308e-05, 3.645717518460055e-05, 3.640262806064877e-05, 3.616314006813733e-05, 3.5930176316653325e-05, 3.543585034278772e-05, 3.533420145085994e-05, 3.5249883492844375e-05, 3.514141319943001e-05, 3.509398327851161e-05, 3.500960577194691e-05, 3.439264266825017e-05, 3.4374159449988484e-05, 3.436678165462554e-05, 3.4319525890997824e-05, 3.41995319961889e-05, 3.391569314087202e-05, 3.383050009267213e-05, 3.367568975125607e-05, 3.354814326251827e-05, 3.3545881332597266e-05, 3.350868647743199e-05, 3.344995911398885e-05, 3.320756354737026e-05, 3.317325269734616e-05, 3.317096885805775e-05, 3.301122542812255e-05, 3.2914076746728286e-05, 3.27994532298084e-05, 3.268611258404443e-05, 3.263526599384106e-05, 3.263153216094051e-05, 3.257035510083201e-05, 3.2521726523336184e-05, 3.250954709098071e-05, 3.248009311833146e-05, 3.24090608788817e-05, 3.235173085395103e-05, 3.2233140268378924e-05, 3.20996067752225e-05, 3.207762652546947e-05, 3.206273884094314e-05, 3.192316682535439e-05, 3.166958989153189e-05, 3.16464602346899e-05, 3.162365129787807e-05, 3.1487788003110265e-05, 3.141547039044721e-05, 3.1343355614900924e-05, 3.1288419019556726e-05, 3.1288301148893375e-05, 3.114687513621021e-05, 3.1017546835352e-05, 3.093481939692673e-05, 3.084769120614707e-05, 3.079567754072016e-05, 3.0776912290364676e-05, 3.07743119509929e-05, 3.077310996027478e-05, 3.0761344149430896e-05, 3.075010268891953e-05, 3.0743269522913855e-05, 3.0697353679422915e-05, 3.042599439785176e-05, 3.0384951232816364e-05, 3.0343618198347623e-05, 3.03243710118463e-05, 3.0172609832268673e-05, 3.0024176527135553e-05, 2.9991204878618897e-05, 2.9875534391590682e-05, 2.9874974393065043e-05, 2.983666525153855e-05, 2.9773637756618838e-05, 2.97060263566207e-05, 2.9689420342520478e-05, 2.9638164290726805e-05, 2.9636182906640394e-05, 2.9588309389428277e-05, 2.94728498252344e-05, 2.9452695528176803e-05, 2.941080745647511e-05, 2.935247925345717e-05, 2.9284578442331665e-05, 2.9274769665242202e-05, 2.9273718043496704e-05, 2.9255125359798494e-05, 2.9219396784479706e-05, 2.9126840517878305e-05, 2.910302787343293e-05, 2.9090650695318195e-05, 2.8873625973692185e-05, 2.881338496382787e-05, 2.8799517919610007e-05, 2.8782322889576614e-05, 2.8735035467718096e-05, 2.8692928852417167e-05, 2.865187986698907e-05, 2.8578645312953684e-05, 2.8510544302121024e-05, 2.8504939619574062e-05, 2.848864308410071e-05, 2.847884932707077e-05, 2.8445099374621833e-05, 2.8410325860153762e-05, 2.839220578081033e-05, 2.838696997012191e-05, 2.8369824294360032e-05, 2.836570951032258e-05, 2.8326349816121165e-05, 2.7995503900112716e-05, 2.7961493607457028e-05, 2.7883971157442917e-05, 2.7872441905831684e-05, 2.7795215198450708e-05, 2.778752123958063e-05, 2.770698076969008e-05, 2.7688999823579156e-05, 2.764676089404711e-05, 2.761709821489653e-05, 2.7607829730435213e-05, 2.760192762619976e-05, 2.757276881108726e-05, 2.7541489204902603e-05, 2.7381492659394265e-05, 2.7352922336724176e-05, 2.7295369738679837e-05, 2.7284262758329365e-05, 2.7196160006542072e-05, 2.710011164757624e-05, 2.708623892984372e-05, 2.7042684980914613e-05, 2.7037396094430637e-05, 2.702995999912912e-05, 2.7021813781040178e-05, 2.7020097068406144e-05, 2.6958046982785696e-05, 2.6956419428163564e-05, 2.6952780769642954e-05, 2.6931598483338175e-05, 2.690311357000532e-05, 2.6782295176612342e-05, 2.672694968412486e-05, 2.6709987048767e-05, 2.6694115571182407e-05, 2.6691315449219008e-05, 2.668352034817774e-05, 2.6669842540250094e-05, 2.6614145658891764e-05, 2.6581483272118763e-05, 2.650148087587105e-05, 2.6487659637555745e-05, 2.6463292839811987e-05, 2.6451887260632855e-05, 2.6446757429658053e-05, 2.6404241684976387e-05, 2.6337217290891113e-05, 2.6319887943233392e-05, 2.6307687354815637e-05, 2.6226989213293953e-05, 2.6194259528381276e-05, 2.617615140958836e-05, 2.6167017931264253e-05, 2.6129051995353715e-05, 2.6083328955778735e-05, 2.601974243171421e-05, 2.6018579318742074e-05, 2.599413232331373e-05, 2.596765931220138e-05, 2.580162850683616e-05, 2.5764019020258793e-05, 2.567022652113456e-05, 2.5630143350965274e-05, 2.5605983831604407e-05, 2.5590175187945958e-05, 2.5568799500885163e-05, 2.5556673988457453e-05, 2.555526285673265e-05, 2.5474831803961214e-05, 2.5443099773347685e-05, 2.5356183582388944e-05, 2.5289504018563916e-05, 2.527079955673868e-05, 2.5259473398771545e-05, 2.5225696624023664e-05, 2.520046197028893e-05, 2.520037729629831e-05, 2.5162499731643372e-05, 2.5147839333451765e-05, 2.5129615659729976e-05, 2.5084134049061784e-05, 2.5077348924453608e-05, 2.5061176954282878e-05, 2.5054255760735267e-05, 2.5046205764417864e-05, 2.5044322578952553e-05, 2.50361780984233e-05, 2.5003516812324508e-05, 2.4994696624409093e-05, 2.4986293392614116e-05, 2.4980009861789155e-05, 2.4979706977315732e-05, 2.4932122452057637e-05, 2.4927144404554656e-05, 2.491420900759817e-05, 2.4904584819992754e-05, 2.488904121475152e-05, 2.484360531724994e-05, 2.4835409466653054e-05, 2.4828742226831778e-05, 2.4794859295409567e-05, 2.4768308603813837e-05, 2.4763293316563905e-05, 2.4759658634318418e-05, 2.47400712716664e-05, 2.4736575070601746e-05, 2.472974942876513e-05, 2.471455977399194e-05, 2.469289493472574e-05, 2.466382067769364e-05, 2.466103062717874e-05, 2.465883282793454e-05, 2.4647392545185677e-05, 2.4633735144701125e-05, 2.4630901754766296e-05, 2.45758419056416e-05, 2.456657100676988e-05, 2.4566419420110996e-05, 2.4564096734716504e-05, 2.4549996147027345e-05, 2.452338555641316e-05, 2.4512893164250915e-05, 2.4504818532543328e-05, 2.448267280582618e-05, 2.4447606219195246e-05, 2.444503980623338e-05, 2.444240453092585e-05, 2.437739915116738e-05, 2.4373053372854014e-05, 2.434168961982304e-05, 2.4338030994317396e-05, 2.4274563483900228e-05, 2.426696670910074e-05, 2.4243279450507786e-05, 2.4243215189718504e-05, 2.4241995806848355e-05, 2.421209073507801e-05, 2.419552289786871e-05, 2.4189126332040964e-05, 2.4182916293374946e-05, 2.4168887433346768e-05, 2.4162484219117087e-05, 2.4161675779988566e-05, 2.4151259820943924e-05, 2.412974781628687e-05, 2.4126812917141326e-05, 2.4125236922407268e-05, 2.41202371560202e-05, 2.4114325569698377e-05, 2.4108625795450026e-05, 2.4067303539748497e-05, 2.4049163060586697e-05, 2.4029254368112043e-05, 2.400769529113761e-05, 2.399904292363105e-05, 2.39970187904336e-05, 2.3983964493780016e-05, 2.398060618736657e-05, 2.3973325468781648e-05, 2.3953402303663513e-05, 2.3949668173723514e-05, 2.3942582613441434e-05, 2.3917885724716906e-05, 2.3912529461996118e-05, 2.3901857695431263e-05, 2.389623280734647e-05, 2.38885353845757e-05, 2.3866712604013444e-05, 2.384053924684617e-05, 2.383699969740245e-05, 2.3835483543766955e-05, 2.3801235825603333e-05, 2.379517032011372e-05, 2.3791614516041795e-05, 2.37818065356703e-05, 2.374633373843743e-05, 2.3721922746467752e-05, 2.3713280888981367e-05, 2.3697403620694823e-05, 2.369690160361716e-05, 2.369576384167043e-05, 2.368360122898735e-05, 2.367375682626256e-05, 2.3656449347910824e-05, 2.364911808507739e-05, 2.362874293371798e-05, 2.3565654196518143e-05, 2.3549693978191205e-05, 2.3538422079698473e-05, 2.3530692719952506e-05, 2.3528640698674977e-05, 2.35218592406801e-05, 2.351798776840594e-05, 2.3516115511665665e-05, 2.349107032185119e-05, 2.3489885030909654e-05, 2.3435913343910206e-05, 2.3409885677673395e-05, 2.3407705667979195e-05, 2.3401654810533455e-05, 2.3383443282618534e-05, 2.338236175733292e-05, 2.337594394785708e-05, 2.3369335800821024e-05, 2.3343451912603984e-05, 2.3337781536824203e-05, 2.331887508117888e-05, 2.3311742160851598e-05, 2.331169736949014e-05, 2.3310129071081092e-05, 2.3305073413858314e-05, 2.330178445787666e-05, 2.3294597558054316e-05, 2.3292737725054446e-05, 2.327997009176017e-05, 2.326467309958889e-05, 2.3257516983995745e-05, 2.323803551756666e-05, 2.323760720279949e-05, 2.321262106722284e-05, 2.3204351258682016e-05, 2.318318223370645e-05, 2.3176070639709437e-05, 2.3173689644607812e-05, 2.3170344690728868e-05, 2.316659794284916e-05, 2.3165819016225404e-05, 2.3149116459908982e-05, 2.3117858824580814e-05, 2.309768779735506e-05, 2.309557907563663e-05, 2.3039385664911117e-05, 2.303593836657486e-05, 2.303160053712879e-05, 2.3029473214911164e-05, 2.3025186258350297e-05, 2.3024030361653104e-05, 2.3022348883961296e-05, 2.2965591492647265e-05, 2.2962073205563486e-05, 2.2922727797204517e-05, 2.291600030687139e-05, 2.2891927853929023e-05, 2.2881315034424115e-05, 2.288055173514431e-05, 2.286964064180511e-05, 2.2853711155760673e-05, 2.283945641049861e-05, 2.2816396093338463e-05, 2.2789179477168687e-05, 2.278256305812138e-05, 2.277445480759594e-05, 2.2769708738510305e-05, 2.2759005515684796e-05, 2.275507755744932e-05, 2.2741856968966392e-05, 2.2737342299213587e-05, 2.27369666070951e-05, 2.2736802583773214e-05, 2.271149655807142e-05, 2.2686921976011107e-05, 2.2659625974790453e-05, 2.2656547334462012e-05, 2.2644030674436595e-05, 2.263904287927695e-05, 2.2624797006070247e-05, 2.261574138118699e-05, 2.261288472312294e-05, 2.2602037823435286e-05, 2.2595267341549817e-05, 2.2592019307531946e-05, 2.2574164530341477e-05, 2.2569873168973117e-05, 2.2569012149678846e-05, 2.2568059664080664e-05, 2.256086401323493e-05, 2.2559554822091406e-05, 2.2556743181007798e-05, 2.2525554660611262e-05, 2.2502348017643572e-05, 2.250095918527869e-05, 2.2496062736986226e-05, 2.2466911678070047e-05, 2.245184769091845e-05, 2.245005205076271e-05, 2.2442487518831043e-05, 2.2438535984436878e-05, 2.2424838551390706e-05, 2.2406045236188817e-05, 2.2406000053948628e-05, 2.240488291633915e-05, 2.2399186284717924e-05, 2.2399173708521973e-05, 2.239706124743517e-05, 2.2390033453501556e-05, 2.238785432448558e-05, 2.238415025966211e-05, 2.2374591949343807e-05, 2.2358290914993245e-05, 2.235691339161462e-05, 2.23516741224632e-05, 2.2348774422289642e-05, 2.233597063423891e-05, 2.233436425036413e-05, 2.2333526037979548e-05, 2.2328511845845673e-05, 2.231856695935034e-05, 2.2287101125633382e-05, 2.226698223004252e-05, 2.2260441719155597e-05, 2.2221308650597146e-05, 2.2207386641660436e-05, 2.2203713704018906e-05, 2.2197711730130992e-05, 2.2197204904105657e-05, 2.219466429979299e-05, 2.2184146359539332e-05, 2.2181193487267105e-05, 2.217627024542395e-05, 2.21608616069069e-05, 2.2146235351273288e-05, 2.2127781420031556e-05, 2.2125583504612557e-05, 2.2122457765610404e-05, 2.21172715562623e-05, 2.211659215452147e-05, 2.2111746702655527e-05, 2.2103377049194562e-05, 2.2095480642320382e-05, 2.2074088451647966e-05, 2.206861260838665e-05, 2.2060066966957565e-05, 2.205932697838526e-05, 2.20531319625151e-05, 2.204736633827368e-05, 2.2046754922167546e-05, 2.2045325071672827e-05, 2.2033937639667722e-05, 2.2029286885549298e-05, 2.2018335965862967e-05, 2.2012833657345737e-05, 2.2001022198002335e-05, 2.200011453791819e-05, 2.1984680310803763e-05, 2.1978260906211073e-05, 2.1964690032110886e-05, 2.1931366878520413e-05, 2.1924723479676462e-05, 2.1916990114987775e-05, 2.188366331432153e-05, 2.1831488928849564e-05, 2.1821241909060583e-05, 2.181979150166132e-05, 2.179440676488719e-05, 2.1793964257721897e-05, 2.1788398076618542e-05, 2.1780089155827454e-05, 2.1772576011495914e-05, 2.1749606705248244e-05, 2.1743017640236777e-05, 2.1731316992378604e-05, 2.1725360471352877e-05, 2.172196131987619e-05, 2.1710007668164796e-05, 2.1674423293205666e-05, 2.167119162953336e-05, 2.1650549912691448e-05, 2.16488718801678e-05, 2.1635008657446744e-05, 2.1619710325194017e-05, 2.161817604206372e-05, 2.1607236709566477e-05, 2.158110872804407e-05, 2.1578691842820025e-05, 2.157203116365295e-05, 2.1565614058684815e-05, 2.1564884321361936e-05, 2.1551403822275997e-05, 2.1545297973461444e-05, 2.152706455834543e-05, 2.1524750422830246e-05, 2.1518531498531025e-05, 2.1509630851689264e-05, 2.149406481964087e-05, 2.1490092748471347e-05, 2.1487277702578777e-05, 2.1487261788221173e-05, 2.148636610284616e-05, 2.148255901458184e-05, 2.147987158573027e-05, 2.145344564916731e-05, 2.1446197824879844e-05, 2.1429365904146677e-05, 2.1417217217313884e-05, 2.1413492774121265e-05, 2.1409722001302882e-05, 2.139085423073782e-05, 2.1383717360557693e-05, 2.138343353598377e-05, 2.1377140650889063e-05, 2.1376832822983492e-05, 2.1368106576370843e-05, 2.1363549423433167e-05, 2.135906636079359e-05, 2.1351472422227432e-05, 2.135001345471814e-05, 2.1346613882465645e-05, 2.134595377584581e-05, 2.134110211863895e-05, 2.1335283504520016e-05, 2.1329704955396336e-05, 2.1326332268797548e-05, 2.132175309534756e-05, 2.1316958320436245e-05, 2.1316037059141055e-05, 2.1306133013299193e-05, 2.1302383329583303e-05, 2.1282635040085747e-05, 2.1256469750156692e-05, 2.1255477329045866e-05, 2.1254792472220634e-05, 2.125252355382788e-05, 2.124094070392322e-05, 2.1232714096571418e-05, 2.123261036168876e-05, 2.1225105547371642e-05, 2.1217232459823225e-05, 2.120896584445679e-05, 2.120674130574501e-05, 2.1198494385941385e-05, 2.1197046766138075e-05, 2.1196163742921205e-05, 2.119073094742695e-05, 2.1180652964409194e-05, 2.1168799146054223e-05, 2.1164639017041063e-05, 2.1159322622031936e-05, 2.115909268791461e-05, 2.115873255831434e-05, 2.1154694597660315e-05, 2.115323448024164e-05, 2.1145768171174997e-05, 2.1141403653656395e-05, 2.1118778209191766e-05, 2.11183617962442e-05, 2.1110890033538406e-05, 2.1109534650584158e-05, 2.1108161902729208e-05, 2.1105685556942573e-05, 2.1105532673869544e-05, 2.10948659021085e-05, 2.1093264209385902e-05, 2.1086532400263755e-05, 2.1086082419933028e-05, 2.108104480539902e-05, 2.1065253683261212e-05, 2.106118193997226e-05, 2.1047311426515086e-05, 2.104682238034996e-05, 2.103253679239776e-05, 2.1026127532418557e-05, 2.1017732882518777e-05, 2.100410044046771e-05, 2.1000523231459196e-05, 2.0971158476355533e-05, 2.096227953594447e-05, 2.0960813185199383e-05, 2.0960666366246903e-05, 2.0954691193057484e-05, 2.09544762735498e-05, 2.0946541272667467e-05, 2.0940507762149336e-05, 2.0936002745555842e-05, 2.0932386531754363e-05, 2.0930788866427762e-05, 2.092133972456327e-05, 2.0913610840327895e-05, 2.091304606731416e-05, 2.0911600696165786e-05, 2.0910532970684765e-05, 2.0906087937460142e-05, 2.0899310932863757e-05, 2.0896245870214235e-05, 2.0884228322718925e-05, 2.0883264301367328e-05, 2.0873083714717716e-05, 2.087064944322684e-05, 2.086286432795255e-05, 2.086147646215693e-05, 2.085752519671269e-05, 2.084595926066184e-05, 2.0842294931730972e-05, 2.083208435770551e-05, 2.0825093053667603e-05, 2.0817726741703543e-05, 2.0810600181479476e-05, 2.0798143223628917e-05, 2.0783884237496718e-05, 2.078194132751425e-05, 2.077949386557486e-05, 2.0771446751893514e-05, 2.0768702530419735e-05, 2.0764252266400108e-05, 2.07470852818504e-05, 2.0743305077065086e-05, 2.074075185204955e-05, 2.0738999757398125e-05, 2.0709713253372662e-05, 2.070645499947558e-05, 2.0701552094492597e-05, 2.06929133186619e-05, 2.0668753219182812e-05, 2.0661375140275354e-05, 2.0640581198556952e-05, 2.062791216557746e-05, 2.0612871899219922e-05, 2.060997164688749e-05, 2.0591294310513538e-05, 2.059126166717407e-05, 2.0583098891317494e-05, 2.057921394292885e-05, 2.0560618110565206e-05, 2.0547032130909412e-05, 2.0545039405345998e-05, 2.0535352722264485e-05, 2.0530449600532895e-05, 2.052380019838742e-05, 2.0518099856015887e-05, 2.0517263121476532e-05, 2.050941336355599e-05, 2.0508529448998516e-05, 2.048003777039364e-05, 2.0465412499946498e-05, 2.045788950593492e-05, 2.0456762593368612e-05, 2.0442779793765562e-05, 2.0439212301966977e-05, 2.0433226970734107e-05, 2.0430067141871187e-05, 2.04210827083204e-05, 2.04177112301753e-05, 2.041640110113088e-05, 2.0411107075073497e-05, 2.0410461583207938e-05, 2.040586469287549e-05, 2.0404336106835285e-05, 2.0400776330753427e-05, 2.038499980181894e-05, 2.0381520798776653e-05, 2.0380489407123468e-05, 2.0361239556328933e-05, 2.035786471062441e-05, 2.034852541816489e-05, 2.033786343367506e-05, 2.0335538778748566e-05, 2.0331145656402466e-05, 2.0302787275300808e-05, 2.0288359741551834e-05, 2.0282014327421245e-05, 2.0274058486377213e-05, 2.0271550421109583e-05, 2.0249315026037024e-05, 2.0240672924580878e-05, 2.0235002548430168e-05, 2.022214498406576e-05, 2.0221636411710757e-05, 2.0199608122244155e-05, 2.017160625080552e-05, 2.017150449912886e-05, 2.0171214493581524e-05, 2.016413947289568e-05, 2.0158210149365712e-05, 2.0154775447118698e-05, 2.0144755775733116e-05, 2.0133469385450838e-05, 2.013072741250717e-05, 2.0129118247859594e-05, 2.012840534078013e-05, 2.012635980633578e-05, 2.0106292716885e-05, 2.010570865419573e-05, 2.0102236790739057e-05, 2.009942775595278e-05, 2.009501191831133e-05, 2.0093547442840807e-05, 2.0093164135818773e-05, 2.008591911772942e-05, 2.0085878176345995e-05, 2.0082947943126252e-05, 2.0077023086217482e-05, 2.0074876561161348e-05, 2.0074399492717513e-05, 2.0071747422374058e-05, 2.0060754501135277e-05, 2.0056754274728216e-05, 2.0050344647705878e-05, 2.0045956035262433e-05, 2.004031586812791e-05, 2.003330470860842e-05, 2.0028216963662546e-05, 2.002445882155133e-05, 2.0024352030917122e-05, 2.002348425301295e-05, 2.0020519274007838e-05, 2.00110251313638e-05, 2.00048767927634e-05, 1.9999962972789396e-05, 1.9985979285760176e-05, 1.998195415250912e-05, 1.9979063053881303e-05, 1.997648415412029e-05, 1.996755980716163e-05, 1.996617806835327e-05, 1.9963481247914862e-05, 1.9957813122056085e-05, 1.994744198271052e-05, 1.994178683655781e-05, 1.9939282215719157e-05, 1.9938739971533956e-05, 1.9937330487473267e-05, 1.9899240135006495e-05, 1.9894251757420876e-05, 1.987932996317489e-05, 1.987366684669439e-05, 1.9868079546165316e-05, 1.9867624924879055e-05, 1.986573294450937e-05, 1.9859686594873604e-05, 1.9857111689139928e-05, 1.985536764871119e-05, 1.985344771786249e-05, 1.9852895882182003e-05, 1.9842622716534415e-05, 1.9836589878641637e-05, 1.9832467485064564e-05, 1.9823659900773006e-05, 1.982264330702239e-05, 1.980782289339566e-05, 1.9799975383131293e-05, 1.979205974328891e-05, 1.9788934593259812e-05, 1.9783486658056745e-05, 1.9782434520555446e-05, 1.976776864396488e-05, 1.9759305086978367e-05, 1.9755332071106367e-05, 1.9751443824480976e-05, 1.9742652613343986e-05, 1.973805601264429e-05, 1.9737183395093986e-05, 1.973577500216199e-05, 1.9725970270533472e-05, 1.9721855646142863e-05, 1.9721061645160486e-05, 1.9718096565749368e-05, 1.970309991992585e-05, 1.9700661024682217e-05, 1.969745669010581e-05, 1.9695294096487347e-05, 1.9695042014063913e-05, 1.9691915087710778e-05, 1.9688614982131102e-05, 1.9688358629955673e-05, 1.9687123854180194e-05, 1.968426133820261e-05, 1.9671447524408697e-05, 1.9668139556179555e-05, 1.9662058563224886e-05, 1.9654599567258396e-05, 1.965122955709351e-05, 1.96365588764194e-05, 1.9630590528589312e-05, 1.9630367941165102e-05, 1.962222237131033e-05, 1.961964523398563e-05, 1.961650092578932e-05, 1.9614533730638095e-05, 1.9607636250736173e-05, 1.9599476602309457e-05, 1.959142078938028e-05, 1.958865831356446e-05, 1.9585111426619992e-05, 1.9584737678028177e-05, 1.9584539322621404e-05, 1.9580612312478013e-05, 1.9575057983527252e-05, 1.9573354443041215e-05, 1.9569614675761884e-05, 1.9566813194869978e-05, 1.9562886700560453e-05, 1.9549970510514945e-05, 1.954465059671927e-05, 1.9532817621005282e-05, 1.953107271091582e-05, 1.9526325185323228e-05, 1.9518906306398377e-05, 1.9516494339728122e-05, 1.951078659310334e-05, 1.950763710602898e-05, 1.950320671732144e-05, 1.9498001210105294e-05, 1.9494923292460742e-05, 1.9493384024492647e-05, 1.9492123072869772e-05, 1.949166535927525e-05, 1.9491550044192323e-05, 1.9482650466804088e-05, 1.9477305634635652e-05, 1.9476105249358248e-05, 1.947605657447901e-05, 1.9474407062335645e-05, 1.9473146465155804e-05, 1.946724155078693e-05, 1.946592752845024e-05, 1.9463203395078578e-05, 1.9457711054133803e-05, 1.945233777233686e-05, 1.9449963358682224e-05, 1.944634819760207e-05, 1.9429792926692357e-05, 1.941142993513974e-05, 1.940639844404121e-05, 1.9403044714841314e-05, 1.939646703241146e-05, 1.9391728397302345e-05, 1.939091272324012e-05, 1.9387423187026047e-05, 1.938214773407574e-05, 1.9381102208130885e-05, 1.938078632609709e-05, 1.9377218695145544e-05, 1.9375214076746825e-05, 1.9373390006359373e-05, 1.9371063769085374e-05, 1.937001876898821e-05, 1.9367458339029913e-05, 1.9361494893912722e-05, 1.935942531077901e-05, 1.9359155903593365e-05, 1.93457581052643e-05, 1.933357197708656e-05, 1.932998220050635e-05, 1.9325176331982506e-05, 1.9322853394188153e-05, 1.9319927860961244e-05, 1.9313447010554023e-05, 1.9301613718781755e-05, 1.9299271293628888e-05, 1.929434072958257e-05, 1.928915220312244e-05, 1.9285861276161883e-05, 1.92815917105614e-05, 1.9280708162152733e-05, 1.9276760634066942e-05, 1.927656889251943e-05, 1.9266557472082892e-05, 1.926518936833416e-05, 1.926074077859925e-05, 1.9256090512983522e-05, 1.9253837851014598e-05, 1.9248608257972127e-05, 1.9245631957915332e-05, 1.9235092834851295e-05, 1.9229044530310424e-05, 1.9228302180050266e-05, 1.9220551751950622e-05, 1.9216383133027603e-05, 1.9216037495800458e-05, 1.9213265503464084e-05, 1.921179756500226e-05, 1.9205492721670854e-05, 1.9193329787707926e-05, 1.918791778413368e-05, 1.9181236534173123e-05, 1.917804965364422e-05, 1.9177959953819434e-05, 1.9173172424786625e-05, 1.9168897834619212e-05, 1.9161619450543775e-05, 1.915986273449942e-05, 1.9155281510194843e-05, 1.9152845428288603e-05, 1.9150148349537862e-05, 1.913491840261454e-05, 1.9131160983494856e-05, 1.9127544493109998e-05, 1.9123467582059033e-05, 1.9121250769263602e-05, 1.9116924285349854e-05, 1.9115327358582173e-05, 1.911335965540081e-05, 1.9111921137554285e-05, 1.910936300801491e-05, 1.9108979237756997e-05, 1.9107427485701313e-05, 1.91050593526876e-05, 1.910019589782814e-05, 1.9095516795268054e-05, 1.9092975466339522e-05, 1.9080674999817715e-05, 1.9080610216081993e-05, 1.907558730940227e-05, 1.9075014512724033e-05, 1.9073331627356044e-05, 1.9068161001289433e-05, 1.9067915287892108e-05, 1.9065126608685244e-05, 1.904724228938347e-05, 1.90407816672242e-05, 1.9039530941612875e-05, 1.903193013328132e-05, 1.9029834338260675e-05, 1.9029597162288013e-05, 1.90288711616123e-05, 1.9025479591619115e-05, 1.90220783561472e-05, 1.9022028459447484e-05, 1.9020888073486447e-05, 1.902028155784944e-05, 1.9013193853957723e-05, 1.900399422613177e-05, 1.8998115661601675e-05, 1.8996327850649182e-05, 1.8987608686973373e-05, 1.898391239238918e-05, 1.8982441041096567e-05, 1.898238503352222e-05, 1.8973570229310107e-05, 1.8970007635823522e-05, 1.8969773432122605e-05, 1.8967550877572545e-05, 1.8962482498349708e-05, 1.8959436182159757e-05, 1.89572451760568e-05, 1.8954457202844674e-05, 1.8950210038094884e-05, 1.894965955248309e-05, 1.89494606098403e-05, 1.8924029970669735e-05, 1.8923102887444788e-05, 1.890594138104142e-05, 1.890311356858599e-05, 1.890244223436922e-05, 1.889985842944246e-05, 1.8897386410736144e-05, 1.888890388396175e-05, 1.8880198317482006e-05, 1.887342015823647e-05, 1.8862784595471394e-05, 1.886083141907542e-05, 1.885967924389845e-05, 1.8852683385255477e-05, 1.8848545425094222e-05, 1.884592552566472e-05, 1.884134646837588e-05, 1.883324511197383e-05, 1.8830596201466578e-05, 1.882920069493009e-05, 1.8816610798378964e-05, 1.88027668526738e-05, 1.880233513640615e-05, 1.880075824269329e-05, 1.8796113551646934e-05, 1.8793307783676066e-05, 1.8789450997382187e-05, 1.8786091462812428e-05, 1.8772418814407846e-05, 1.8768823367830395e-05, 1.8760199663360105e-05, 1.875999407312992e-05, 1.875657137819555e-05, 1.874394154625618e-05, 1.8740576548042798e-05, 1.8739346163644744e-05, 1.873470754226675e-05, 1.8731377877704266e-05, 1.873110145363172e-05, 1.8730523418181195e-05, 1.8722729653806282e-05, 1.871776192563583e-05, 1.870222317155926e-05, 1.8698654869106004e-05, 1.869675711398081e-05, 1.8692165598255055e-05, 1.8688620145587925e-05, 1.868208175393207e-05, 1.867470520117793e-05, 1.8670143321174623e-05, 1.8665790754021302e-05, 1.8662944317568296e-05, 1.8658360591886482e-05, 1.8657871344153858e-05, 1.8653444854699433e-05, 1.8652657879778002e-05, 1.8645881494272234e-05, 1.864565205281211e-05, 1.8644364542430415e-05, 1.8640773163509464e-05, 1.8634884270439154e-05, 1.863438160232372e-05, 1.863389447766051e-05, 1.8629831709653545e-05, 1.862232601549411e-05, 1.8621494621230336e-05, 1.861819079098014e-05, 1.8617897436386104e-05, 1.8614811406359906e-05, 1.8614202046444406e-05, 1.861394567961745e-05, 1.8609715732815935e-05, 1.8609222910715623e-05, 1.8605669321786264e-05, 1.8600010866583744e-05, 1.859872981033722e-05, 1.8598144448475042e-05, 1.859571491025011e-05, 1.8592686611657596e-05, 1.8591460204138068e-05, 1.8591167008197516e-05, 1.858517785701933e-05, 1.8579356197437437e-05, 1.8576680925194905e-05, 1.857408934502986e-05, 1.857108900277894e-05, 1.856894445788488e-05, 1.8567377431804466e-05, 1.8565236352535185e-05, 1.8560887247126102e-05, 1.855789777439826e-05, 1.854866257756456e-05, 1.8547678674367987e-05, 1.8541587223429683e-05, 1.8539342029223408e-05, 1.853248332958092e-05, 1.8529553172139725e-05, 1.852611589417754e-05, 1.8523499208606624e-05, 1.85222526953609e-05, 1.8520828335002222e-05, 1.851456013148275e-05, 1.8510264430531895e-05, 1.850856981369943e-05, 1.8499500187303536e-05, 1.8499137986844865e-05, 1.849450995452677e-05, 1.848265991862326e-05, 1.8479947319177096e-05, 1.8478755694540407e-05, 1.8473996776811262e-05, 1.8473301224874448e-05, 1.8470193393554705e-05, 1.8469288808049703e-05, 1.8464986193147007e-05, 1.8464674526838774e-05, 1.8462422613221596e-05, 1.8461920761322176e-05, 1.845811116373239e-05, 1.8452888298018315e-05, 1.844764325499709e-05, 1.8445855293994554e-05, 1.8439958850473946e-05, 1.8436559417102242e-05, 1.843534690921525e-05, 1.84346596531318e-05, 1.8424774810354204e-05, 1.8410588067882657e-05, 1.8406680475288225e-05, 1.8404881584848195e-05, 1.8400838438531643e-05, 1.839952034020983e-05, 1.839800870796167e-05, 1.8395534534755674e-05, 1.839194010764955e-05, 1.839151369806096e-05, 1.8389041145346163e-05, 1.8387340232792144e-05, 1.8382306685755335e-05, 1.838160216649746e-05, 1.8377139967380046e-05, 1.837030235306874e-05, 1.8364488659844e-05, 1.8363111570241988e-05, 1.836050928033711e-05, 1.8358692704858785e-05, 1.835797583817146e-05, 1.835723843430131e-05, 1.835603962198258e-05, 1.8355326070680737e-05, 1.8352579699738848e-05, 1.8348662539393507e-05, 1.834837617709946e-05, 1.8346115192141348e-05, 1.8342824939817125e-05, 1.833799439501802e-05, 1.833289499187409e-05, 1.8330314685846946e-05, 1.832485758254456e-05, 1.8320098540249925e-05, 1.831786113303979e-05, 1.831754193942234e-05, 1.831203131100345e-05, 1.829967424998816e-05, 1.8296303684670827e-05, 1.8295838092704323e-05, 1.82900283071388e-05, 1.82878983767122e-05, 1.8287253534267263e-05, 1.82870339778924e-05, 1.8286782836339146e-05, 1.827500938946533e-05, 1.8269317877458863e-05, 1.826575676393502e-05, 1.826409852026933e-05, 1.8258832919063687e-05, 1.8253901806487134e-05, 1.8253784088775823e-05, 1.8251669260109326e-05, 1.8250570502763645e-05, 1.824847211665668e-05, 1.8248344506813053e-05, 1.8246369940842277e-05, 1.8230596741631485e-05, 1.822735407356635e-05, 1.82267992659737e-05, 1.822436353802498e-05, 1.8223123418105053e-05, 1.8221880330697425e-05, 1.8214928796820154e-05, 1.8214174980102333e-05, 1.821119628058437e-05, 1.8209419872422815e-05, 1.8207606809176675e-05, 1.81989916837479e-05, 1.8196618447856423e-05, 1.8196057017225834e-05, 1.8195079945303017e-05, 1.8192277324087063e-05, 1.8189815693604856e-05, 1.818967191704441e-05, 1.818967052048582e-05, 1.8183207226375025e-05, 1.8179288173006064e-05, 1.817099091631033e-05, 1.8166835964713036e-05, 1.8166046830885715e-05, 1.8165830789895947e-05, 1.815486244690987e-05, 1.8153619396627132e-05, 1.8153316210570414e-05, 1.8150977500875688e-05, 1.8146412100429883e-05, 1.8145672248388486e-05, 1.814201902959369e-05, 1.8141218852802855e-05, 1.8139241812519895e-05, 1.8121657201857637e-05, 1.8120528788869787e-05, 1.8120420969239464e-05, 1.8118238703818046e-05, 1.8113833503635643e-05, 1.8112926245888693e-05, 1.810691953097407e-05, 1.8104596485349752e-05, 1.8103111885292395e-05, 1.80996748799505e-05, 1.809929360205421e-05, 1.809905599757314e-05, 1.8098411404247022e-05, 1.8084724389225966e-05, 1.8084232140808148e-05, 1.8083327704757183e-05, 1.808049144342437e-05, 1.8079352832049985e-05, 1.8079144583713682e-05, 1.80782398933248e-05, 1.8075570258337844e-05, 1.8075350326169352e-05, 1.807465810099689e-05, 1.807189593753954e-05, 1.806730675316146e-05, 1.8066524936796772e-05, 1.8063076080492885e-05, 1.8060272700461743e-05, 1.8053869579678038e-05, 1.8047021521002816e-05, 1.804496274807248e-05, 1.804383931175513e-05, 1.8040375979578227e-05, 1.803552831503082e-05, 1.8031138732586597e-05, 1.802940208049145e-05, 1.80269955835341e-05, 1.8024129633422783e-05, 1.8015555867604228e-05, 1.8012172939653273e-05, 1.8010686787789967e-05, 1.8009465061994187e-05, 1.8001882358622276e-05, 1.799966412858127e-05, 1.7994462062557555e-05, 1.7989224902345936e-05, 1.7988884191185852e-05, 1.7986214274575683e-05, 1.7985946512532903e-05, 1.7983679867058983e-05, 1.797894525413863e-05, 1.7978592832552935e-05, 1.7977690374654933e-05, 1.797761005425188e-05, 1.7976037342054594e-05, 1.7974982050966854e-05, 1.797447216972893e-05, 1.7971222915740003e-05, 1.7969660007132206e-05, 1.796171651408994e-05, 1.7957155224603104e-05, 1.795655356121839e-05, 1.795621381554248e-05, 1.7937967821574315e-05, 1.7937702031275626e-05, 1.7936877336351157e-05, 1.7936738353930513e-05, 1.7930084966552897e-05, 1.7927975225822318e-05, 1.79227244109107e-05, 1.7922089479178138e-05, 1.791881579583946e-05, 1.79182163931121e-05, 1.7914255199504895e-05, 1.7911202684657288e-05, 1.7902197534155187e-05, 1.7901947028413555e-05, 1.7901515443932565e-05, 1.790066856122406e-05, 1.7896488857631373e-05, 1.789632660793911e-05, 1.789503807642761e-05, 1.7891991843033315e-05, 1.7887807232909796e-05, 1.7883834111424534e-05, 1.788032512764961e-05, 1.7876634947328984e-05, 1.7875234093139608e-05, 1.7874135315366133e-05, 1.7873220043698486e-05, 1.7871267572178832e-05, 1.7868677058869075e-05, 1.7866469027048582e-05, 1.7866009040857352e-05, 1.7865843607590623e-05, 1.785408185100836e-05, 1.7852678734186128e-05, 1.7848492293603146e-05, 1.784622269917329e-05, 1.7839051721547004e-05, 1.7837715499634034e-05, 1.7830978319148048e-05, 1.782828548168204e-05, 1.7828118420412744e-05, 1.782810374176721e-05, 1.7826117618401603e-05, 1.782392653405955e-05, 1.7822504752923364e-05, 1.7819497573650075e-05, 1.78135994069788e-05, 1.7812469528269432e-05, 1.781028204976863e-05, 1.7810064377812103e-05, 1.7808442710228428e-05, 1.7808239833054044e-05, 1.7798213410330726e-05, 1.7797862760125348e-05, 1.779727800455701e-05, 1.7794356573093185e-05, 1.7791922339796887e-05, 1.7791522483287415e-05, 1.7790810462228058e-05, 1.7790647829854727e-05, 1.7790478830439597e-05, 1.7788883524183865e-05, 1.7786376898331106e-05, 1.7780209416073352e-05, 1.7772332728695702e-05, 1.777083408495657e-05, 1.77706793927738e-05, 1.7757787262232706e-05, 1.77562477065176e-05, 1.7753433027199213e-05, 1.774594081096576e-05, 1.7745140539885346e-05, 1.7745104391380855e-05, 1.773719225807084e-05, 1.773651015788269e-05, 1.7728890268906108e-05, 1.7718063638011397e-05, 1.7717045620995388e-05, 1.7709316675762286e-05, 1.770918176125559e-05, 1.7708327687765395e-05, 1.7700857994381353e-05, 1.770076928276469e-05, 1.7697258058028793e-05, 1.7695943211981652e-05, 1.7695825930485983e-05, 1.769569622123829e-05, 1.7693557879244338e-05, 1.7692703395910876e-05, 1.7690350166586687e-05, 1.7689678945318684e-05, 1.7685961190889395e-05, 1.7684860974739208e-05, 1.7684112369262995e-05, 1.7676384790043844e-05, 1.767272029951386e-05, 1.7672134230590062e-05, 1.7667873399374473e-05, 1.7665737961855792e-05, 1.766532725721695e-05, 1.7663799944693975e-05, 1.7663525094604242e-05, 1.7662974956914123e-05, 1.7660838172109237e-05, 1.7659593961354423e-05, 1.7659584637258142e-05, 1.7659417471206603e-05, 1.7656872293373043e-05, 1.7653352355594394e-05, 1.7653213233207294e-05, 1.7646614632889127e-05, 1.7642189827001938e-05, 1.763252404483445e-05, 1.763109600637839e-05, 1.7630726596593628e-05, 1.762805067021758e-05, 1.762799071366646e-05, 1.7627198789376472e-05, 1.7625336236230954e-05, 1.7624427773111756e-05, 1.761333914167678e-05, 1.761227633740246e-05, 1.7609010605909963e-05, 1.7604751943578204e-05, 1.7604480664839643e-05, 1.7603278935569033e-05, 1.7600406795404542e-05, 1.7598089064209817e-05, 1.759241895875747e-05, 1.758549573814206e-05, 1.7585370025405026e-05, 1.758316548554788e-05, 1.758094006184839e-05, 1.7576775886143957e-05, 1.7576123222120593e-05, 1.7575774999481016e-05, 1.7575276242191255e-05, 1.7575203507079193e-05, 1.7574891118681075e-05, 1.7567843953238264e-05, 1.756479691024289e-05, 1.7564021640893775e-05, 1.7558091889061827e-05, 1.7556562637290168e-05, 1.754652910511682e-05, 1.753947627616943e-05, 1.75374991340675e-05, 1.753685276019903e-05, 1.7536389274282753e-05, 1.753584586926048e-05, 1.753519155001872e-05, 1.7533321012532e-05, 1.7532368012736886e-05, 1.753140006351056e-05, 1.7531388932653264e-05, 1.752922384140796e-05, 1.752814758369249e-05, 1.752700612583533e-05, 1.7526021274319655e-05, 1.7519993270157377e-05, 1.7519977035750366e-05, 1.7518982251998573e-05, 1.7518118480032555e-05, 1.7515194518266238e-05, 1.751269074335144e-05, 1.7509264272650277e-05, 1.750857559417436e-05, 1.7507819488304717e-05, 1.750699223044687e-05, 1.7505818836072043e-05, 1.750534461364096e-05, 1.7501305096178004e-05, 1.7499322610565073e-05, 1.749629664535156e-05, 1.749431765237027e-05, 1.749381156912698e-05, 1.7493562308396216e-05, 1.7479947907423906e-05, 1.7479265451680913e-05, 1.74789731017431e-05, 1.74762972725002e-05, 1.7472026911400972e-05, 1.7470727158841835e-05, 1.7467653841671503e-05, 1.7462977851222558e-05, 1.746146641602039e-05, 1.7456453348671697e-05, 1.7456174267911652e-05, 1.7453883225163962e-05, 1.745380786401846e-05, 1.7444725020312888e-05, 1.7442399429666954e-05, 1.743278699919498e-05, 1.7431630061266655e-05, 1.742990338071424e-05, 1.7429000187705725e-05, 1.7427065157657492e-05, 1.7426582725920718e-05, 1.7422685066152257e-05, 1.741995327763836e-05, 1.7418251313457998e-05, 1.741494937679361e-05, 1.7407162077294363e-05, 1.7406925333566843e-05, 1.740436403757261e-05, 1.7399820865911672e-05, 1.739761412216518e-05, 1.7394301082708444e-05, 1.739182406647058e-05, 1.7390512156834224e-05, 1.738537124225762e-05, 1.7384614431503426e-05, 1.7384486865001716e-05, 1.737753579080014e-05, 1.7376969606472265e-05, 1.7374355546390432e-05, 1.7372604769711268e-05, 1.7369000617108502e-05, 1.736715413581753e-05, 1.7366277719458446e-05, 1.7358675769665383e-05, 1.7357641673088094e-05, 1.7355561389437808e-05, 1.7353912459972812e-05, 1.735094978463065e-05, 1.7350029621756584e-05, 1.734924654726818e-05, 1.7348186703691438e-05, 1.734689125531606e-05, 1.7346297160997367e-05, 1.7345638657829446e-05, 1.7342084150552985e-05, 1.7341122665969815e-05, 1.7340277609408545e-05, 1.733870165910473e-05, 1.7330277766044068e-05, 1.7326169108813825e-05, 1.732448425476616e-05, 1.73242991255852e-05, 1.7324139735569407e-05, 1.732241045395504e-05, 1.7319892548733678e-05, 1.7318352587947024e-05, 1.7317273788242054e-05, 1.7314124150678135e-05, 1.730868062364223e-05, 1.7306582940173102e-05, 1.7305076468191467e-05, 1.7303553641067124e-05, 1.7303121820363913e-05, 1.7300698162060323e-05, 1.7297781789687743e-05, 1.7291511605291542e-05, 1.728926262218362e-05, 1.7286024066102376e-05, 1.728474810410395e-05, 1.7280069949912037e-05, 1.7265902778250896e-05, 1.7263753460423793e-05, 1.726260722892645e-05, 1.7259019914443286e-05, 1.7257836801042275e-05, 1.7255037278764843e-05, 1.7254021188854417e-05, 1.7253993739235403e-05, 1.7253917952960463e-05, 1.725343520670772e-05, 1.7250560784257785e-05, 1.724563442308817e-05, 1.7244075321781435e-05, 1.7243887729914722e-05, 1.7243228908506747e-05, 1.7236953534905808e-05, 1.7235410721207333e-05, 1.723362841741698e-05, 1.7227478932789155e-05, 1.7221831118604325e-05, 1.7218079454536968e-05, 1.7214626398221475e-05, 1.7213008660678236e-05, 1.7209879127002455e-05, 1.7206327293090976e-05, 1.720559915880062e-05, 1.720537108193628e-05, 1.7205362044599902e-05, 1.7203866066443043e-05, 1.7202907365095686e-05, 1.720117326768835e-05, 1.7198132949997667e-05, 1.7197774710326365e-05, 1.719614735092415e-05, 1.71952070751547e-05, 1.7195129540656766e-05, 1.719492861854387e-05, 1.719305586808227e-05, 1.7190895953901178e-05, 1.718806168937202e-05, 1.7182960237813684e-05, 1.7180400446117534e-05, 1.717903356626375e-05, 1.7177645516953792e-05, 1.7176396287141976e-05, 1.717627605697539e-05, 1.7175835174727218e-05, 1.717572812124336e-05, 1.7174739664016805e-05, 1.7172110595653692e-05, 1.717101425685658e-05, 1.7168225542391098e-05, 1.716710071818639e-05, 1.7158340721450346e-05, 1.71580488866841e-05, 1.7154574751671256e-05, 1.71544137549511e-05, 1.715279023094244e-05, 1.714726289124145e-05, 1.7142176223914787e-05, 1.7139901812848955e-05, 1.7135584691245826e-05, 1.713483781203028e-05, 1.7133863902754302e-05, 1.7129509273573557e-05, 1.712859745259205e-05, 1.7128524836639063e-05, 1.712760116766895e-05, 1.712631165343606e-05, 1.7126153402710617e-05, 1.7124517818174282e-05, 1.7123862369527088e-05, 1.7121121134933143e-05, 1.7120483533038264e-05, 1.7119069950200858e-05, 1.7118646868829363e-05, 1.711825810907472e-05, 1.7116964471682982e-05, 1.7115450880604775e-05, 1.7113056965369644e-05, 1.7112695181634946e-05, 1.7111214089139472e-05, 1.7105286979791445e-05, 1.709571143219052e-05, 1.7095148857616322e-05, 1.7094836142923816e-05, 1.70926439570216e-05, 1.7086708371678337e-05, 1.708552776170098e-05, 1.7079726690933943e-05, 1.707649461562749e-05, 1.7076325198440774e-05, 1.7070702247934785e-05, 1.7069558231287905e-05, 1.706711631121522e-05, 1.7063032396092796e-05, 1.706174803862806e-05, 1.706083321670151e-05, 1.7060166161573815e-05, 1.7059461690818904e-05, 1.705710180172782e-05, 1.70559228840647e-05, 1.7055369589038588e-05, 1.7054793093764147e-05, 1.7054285505324545e-05, 1.7053029133757843e-05, 1.7050023261611463e-05, 1.7049675707778642e-05, 1.704866975705082e-05, 1.7048637742881318e-05, 1.7047247082119262e-05, 1.7046687726052138e-05, 1.7043631097124422e-05, 1.7042752877887265e-05, 1.7040940408159886e-05, 1.7040570477353144e-05, 1.704029515522431e-05, 1.7038031996732776e-05, 1.7032308127938802e-05, 1.7032060159965174e-05, 1.7031545826423657e-05, 1.703067228635689e-05, 1.7028084369777014e-05, 1.7026434008186048e-05, 1.7022748147578676e-05, 1.7016357944925315e-05, 1.7012349046070485e-05, 1.7010728606206565e-05, 1.7009674999626935e-05, 1.700941079145401e-05, 1.7006242004789207e-05, 1.7006157530887087e-05, 1.700536910163673e-05, 1.7002032860609264e-05, 1.7001843107928333e-05, 1.7001134245030306e-05, 1.699802856173739e-05, 1.699240815600602e-05, 1.6988675998362973e-05, 1.6984013763111143e-05, 1.6981493003986436e-05, 1.6973800848224123e-05, 1.6973512978746234e-05, 1.6972257974963358e-05, 1.6971769476711275e-05, 1.6967254043353752e-05, 1.6967224449942775e-05, 1.6963700063749165e-05, 1.6962473988974377e-05, 1.6960915787478786e-05, 1.695958141388851e-05, 1.6952604736350463e-05, 1.6951170679585117e-05, 1.6950184184366898e-05, 1.69456003879613e-05, 1.694224265597202e-05, 1.6937753801367304e-05, 1.6937693713156245e-05, 1.6933812203852624e-05, 1.6933261234619283e-05, 1.6931606270885306e-05, 1.6930286147557477e-05, 1.692987596958273e-05, 1.692584655291749e-05, 1.6925611605538737e-05, 1.691375954850359e-05, 1.691020475562458e-05, 1.6908707477227618e-05, 1.6904984515961525e-05, 1.6904014826441452e-05, 1.690329015706901e-05, 1.690326577391554e-05, 1.690160937887132e-05, 1.6900879146138332e-05, 1.689443718305587e-05, 1.6894184208011957e-05, 1.689369897340263e-05, 1.6881363587834637e-05, 1.6876746748068792e-05, 1.6873929545111628e-05, 1.68735890722836e-05, 1.687078859981582e-05, 1.686879579013171e-05, 1.6867566195855466e-05, 1.6861101390394832e-05, 1.6860724519221878e-05, 1.6859520498726062e-05, 1.6857565070864735e-05, 1.6857125099644085e-05, 1.685601469900274e-05, 1.685595229774277e-05, 1.6854633226879455e-05, 1.6850777998618938e-05, 1.685039185014903e-05, 1.6849498173088455e-05, 1.6847064131253777e-05, 1.684623662304248e-05, 1.684516720750697e-05, 1.6841594643139372e-05, 1.6837544732936426e-05, 1.683732154139641e-05, 1.683318414242685e-05, 1.6828745441199062e-05, 1.6825964114905087e-05, 1.682196793087856e-05, 1.6819995351822905e-05, 1.6816536536491474e-05, 1.6814994019204867e-05, 1.681366846737661e-05, 1.681166393836113e-05, 1.6807957186316807e-05, 1.680705048067848e-05, 1.680202673667905e-05, 1.6801752160165346e-05, 1.6800269667355075e-05, 1.6800188429028506e-05, 1.6798356194888886e-05, 1.6797978201928877e-05, 1.6795461186646402e-05, 1.6790158498296058e-05, 1.678884101688929e-05, 1.678714051357644e-05, 1.6786007845300122e-05, 1.6782571242518504e-05, 1.67817419705289e-05, 1.677348687290536e-05, 1.6770306318161917e-05, 1.676664511471082e-05]\n",
      "our threshold:  5e-05\n",
      "CPU times: user 53min 21s, sys: 1min 5s, total: 54min 26s\n",
      "Wall time: 54min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_embeddings = predict_embeddings(prediction_model, Y_flow)\n",
    "y_pred_ids = embeddings_to_ids(y_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1004225b",
   "metadata": {
    "papermill": {
     "duration": 22.049238,
     "end_time": "2022-04-18T19:33:41.911960",
     "exception": false,
     "start_time": "2022-04-18T19:33:19.862722",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Visualizing testing set's embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "111b664e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T19:34:24.643344Z",
     "iopub.status.busy": "2022-04-18T19:34:24.641660Z",
     "iopub.status.idle": "2022-04-18T19:34:24.645780Z",
     "shell.execute_reply": "2022-04-18T19:34:24.645129Z",
     "shell.execute_reply.started": "2022-04-18T08:43:42.944314Z"
    },
    "papermill": {
     "duration": 21.140114,
     "end_time": "2022-04-18T19:34:24.645936",
     "exception": false,
     "start_time": "2022-04-18T19:34:03.505822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 6.44 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# scatter3D(y_embeddings, np.array(y_pred_ids)[:,0], train_df['individual_id'].unique().tolist()+['new_individual'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7987ed",
   "metadata": {
    "papermill": {
     "duration": 21.40892,
     "end_time": "2022-04-18T19:35:08.093642",
     "exception": false,
     "start_time": "2022-04-18T19:34:46.684722",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Submission preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d352fb76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T19:35:51.329675Z",
     "iopub.status.busy": "2022-04-18T19:35:51.328794Z",
     "iopub.status.idle": "2022-04-18T19:35:51.352860Z",
     "shell.execute_reply": "2022-04-18T19:35:51.353426Z",
     "shell.execute_reply.started": "2022-04-18T08:43:42.951729Z"
    },
    "papermill": {
     "duration": 21.751774,
     "end_time": "2022-04-18T19:35:51.353582",
     "exception": false,
     "start_time": "2022-04-18T19:35:29.601808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.5 ms, sys: 1.01 ms, total: 24.5 ms\n",
      "Wall time: 24.1 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cd50701ae53ed8.jpg</td>\n",
       "      <td>0f72263cd384 5eb72a46aa6c 938b7e931166 b90d49ab0905 bc48b7c97463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>177269f927ed34.jpg</td>\n",
       "      <td>9070d4778a52 f4a45e49df72 b3ddd5b1f9bc 6f021f47ab3a 4c47fe2b6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9137934396d804.jpg</td>\n",
       "      <td>1e802c3294cc 51081e431bca d9da9aa05a90 aeae6f5bf5cd a52e4ad2dbb3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c28365a55a0dfe.jpg</td>\n",
       "      <td>2a76791b975d 4d18b20adff3 b7065da154c5 b54c1f8df53f ebb6f9c885f9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1a40b7b382923a.jpg</td>\n",
       "      <td>091b540fb82e e5c50e5f2e52 29d62ab98b53 cb3ab35e8dfa fcc7ade0c50a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0eb65d9495a8ad.jpg</td>\n",
       "      <td>ddca2dbdf9c0 2dd8974deb39 7a58308da755 ede672637a68 7a25857bbcfc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3cf81d69cc5911.jpg</td>\n",
       "      <td>9e89f8e28807 d36d5a07500f bc1eb2241633 51f29ea40aeb f36c618eda4a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bade5ab0f99289.jpg</td>\n",
       "      <td>d46efdc12fc2 3cdec3c60be9 29cb5ccedb51 a91388b5d86f 5fc809d9e819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>036dc852e2ec94.jpg</td>\n",
       "      <td>339e32b3b3d1 be944362657a c02b389616b5 6a767e4dc395 50c307188621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1c5bced4d28e48.jpg</td>\n",
       "      <td>44bd3fec6ad6 da65f819073c 6818edefecc9 7845337998d6 8e5253662392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                image                                                       predictions\n",
       "0  cd50701ae53ed8.jpg  0f72263cd384 5eb72a46aa6c 938b7e931166 b90d49ab0905 bc48b7c97463\n",
       "1  177269f927ed34.jpg  9070d4778a52 f4a45e49df72 b3ddd5b1f9bc 6f021f47ab3a 4c47fe2b6931\n",
       "2  9137934396d804.jpg  1e802c3294cc 51081e431bca d9da9aa05a90 aeae6f5bf5cd a52e4ad2dbb3\n",
       "3  c28365a55a0dfe.jpg  2a76791b975d 4d18b20adff3 b7065da154c5 b54c1f8df53f ebb6f9c885f9\n",
       "4  1a40b7b382923a.jpg  091b540fb82e e5c50e5f2e52 29d62ab98b53 cb3ab35e8dfa fcc7ade0c50a\n",
       "5  0eb65d9495a8ad.jpg  ddca2dbdf9c0 2dd8974deb39 7a58308da755 ede672637a68 7a25857bbcfc\n",
       "6  3cf81d69cc5911.jpg  9e89f8e28807 d36d5a07500f bc1eb2241633 51f29ea40aeb f36c618eda4a\n",
       "7  bade5ab0f99289.jpg  d46efdc12fc2 3cdec3c60be9 29cb5ccedb51 a91388b5d86f 5fc809d9e819\n",
       "8  036dc852e2ec94.jpg  339e32b3b3d1 be944362657a c02b389616b5 6a767e4dc395 50c307188621\n",
       "9  1c5bced4d28e48.jpg  44bd3fec6ad6 da65f819073c 6818edefecc9 7845337998d6 8e5253662392"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "str_y_pred_ids = [' '.join(label_list) for label_list in y_pred_ids]\n",
    "\n",
    "test_df.loc[:len(str_y_pred_ids)-1,'predictions'] = str_y_pred_ids\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba4573cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T19:36:34.885734Z",
     "iopub.status.busy": "2022-04-18T19:36:34.884863Z",
     "iopub.status.idle": "2022-04-18T19:36:35.046597Z",
     "shell.execute_reply": "2022-04-18T19:36:35.047029Z",
     "shell.execute_reply.started": "2022-04-18T08:43:42.970608Z"
    },
    "papermill": {
     "duration": 22.339938,
     "end_time": "2022-04-18T19:36:35.047175",
     "exception": false,
     "start_time": "2022-04-18T19:36:12.707237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27956</td>\n",
       "      <td>27956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>27956</td>\n",
       "      <td>27947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>cd50701ae53ed8.jpg</td>\n",
       "      <td>new_individual 5f80a6446397 9103a95dee61 be0d0fc07a33 4b00fe572063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     image                                                         predictions\n",
       "count                27956                                                               27956\n",
       "unique               27956                                                               27947\n",
       "top     cd50701ae53ed8.jpg  new_individual 5f80a6446397 9103a95dee61 be0d0fc07a33 4b00fe572063\n",
       "freq                     1                                                                   2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.to_csv('submission.csv',index=False)\n",
    "test_df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 39104.263066,
   "end_time": "2022-04-18T19:36:59.894453",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-18T08:45:15.631387",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
